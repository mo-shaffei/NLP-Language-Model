{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook we investigate a language model that uses four grams and five grams to generate sequences using a words from a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zAsU-lGrD2yD"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "f = open(\"9053.txt\", \"r\")  # open the dataset\n",
    "Dataset = []\n",
    "for line in f:  # clean the dataset\n",
    "    line = re.sub(r'\\@\\@\\d{8} \\@\\d{7}/','',line)\n",
    "    line = re.sub(r'<h>|<p>','',line)\n",
    "    line = re.sub(r'  ',' ',line)\n",
    "    line = re.sub(r'\\@','',line)\n",
    "    Dataset.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_gram(string):\n",
    "    '''\n",
    "    take a string and return a list containing lists of all possible four grams in this string\n",
    "    '''\n",
    "    \n",
    "    string = \"<START> \"+ string +\" <END>\"\n",
    "    word_list = string.split(' ')\n",
    "    FourGrams = []\n",
    "    for i in range(len(word_list)-3):\n",
    "        FourGrams.append([word_list[i],word_list[i+1],word_list[i+2], word_list[i+3]])\n",
    "    return FourGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<START>', 'Hello', 'world', 'today'],\n",
       " ['Hello', 'world', 'today', 'is'],\n",
       " ['world', 'today', 'is', 'good'],\n",
       " ['today', 'is', 'good', '<END>']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the four_gram function\n",
    "string = \"Hello world today is good\"\n",
    "four_gram(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_gram(string):\n",
    "    '''\n",
    "    take a string and return a list containing lists of all possible five grams in this string\n",
    "    '''\n",
    "    string = \"<START> \"+ string +\" <END>\"\n",
    "    word_list = string.split(' ')\n",
    "    FiveGrams = []\n",
    "    for i in range(len(word_list)-4):\n",
    "        FiveGrams.append([word_list[i],word_list[i+1],word_list[i+2], word_list[i+3], word_list[i+4]])\n",
    "    return FiveGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<START>', 'Hello', 'world', 'today', 'is'],\n",
       " ['Hello', 'world', 'today', 'is', 'good'],\n",
       " ['world', 'today', 'is', 'good', '<END>']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the four_gram function\n",
    "string = \"Hello world today is good\"\n",
    "five_gram(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "Total_Count = 0  # init count to zereo\n",
    "FourGram_Dict = defaultdict(lambda: defaultdict(lambda: 0))  # init fourgramdict to zeros\n",
    "for line in Dataset:  # get one line at a time from the dataset\n",
    "    list_of_grams = four_gram(line)  # get all possible four grams in this line\n",
    "    Total_Count += len(list_of_grams)  # increment total_count\n",
    "    for w1,w2,w3,w4 in list_of_grams:  # inrcease the occurence of the 4th word after the first 3 words\n",
    "        FourGram_Dict[(w1, w2, w3)][w4] += 1\n",
    "        \n",
    "for w1_w2_w3 in FourGram_Dict:  # normalize the counts to get the probabilities\n",
    "    for w4 in FourGram_Dict[w1_w2_w3]:\n",
    "        FourGram_Dict[w1_w2_w3][w4] /=  Total_Count\n",
    "\n",
    "# generate a list of all possible start sequences in the dictionary\n",
    "start_sequences_4 = [fourgrams for fourgrams in list(FourGram_Dict.keys()) if fourgrams[0] == '<START>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below code does the same as the cell above but for 5 grams\n",
    "\n",
    "Total_Count = 0\n",
    "FiveGram_Dict = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for line in Dataset:\n",
    "    list_of_grams = five_gram(line)\n",
    "    Total_Count += len(list_of_grams)\n",
    "    for w1,w2,w3,w4,w5 in list_of_grams:\n",
    "        FiveGram_Dict[(w1, w2, w3, w4)][w5] += 1\n",
    "        \n",
    "for w1_w2_w3_w4 in FourGram_Dict:\n",
    "    for w5 in FourGram_Dict[w1_w2_w3_w4]:\n",
    "        FiveGram_Dict[w1_w2_w3_w4][w5] /=  Total_Count\n",
    "        \n",
    "start_sequences_5 = [fivegrams for fivegrams in list(FiveGram_Dict.keys()) if fivegrams[0] == '<START>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_rand_seq(word_dict, max_len, start_sequences, n):\n",
    "    '''\n",
    "    generate a random sequence give the word_dict. sequence has a maximum length of max_len.\n",
    "    choose a start sequence randomly from the list of start_sequnces. n is the number of previous words\n",
    "    used to predict the next word.\n",
    "    '''\n",
    "    \n",
    "    seq = list(random.choice(start_sequences)) # get a random start sequence\n",
    "    length = len(seq)  # get the initial length of the sequnce\n",
    "    while length <= max_len:  # keep addin more words as long as max_len is not achieved\n",
    "        # get a list of all possible words to generat given the last n words from the sequence\n",
    "        possible_words = list((word_dict[tuple(seq[-n:])]).keys())\n",
    "        if possible_words:  # if there is at least one possible new word\n",
    "            new_word = random.choice(possible_words)  # pick the new word randomly from all possible new words\n",
    "            seq.append(new_word)  # append the new word to the sequence\n",
    "            if new_word.strip() == '.':  # if the new word is a . then the sentence is over\n",
    "                seq.pop(0)  # remove the start token\n",
    "                return ' '.join(seq)  # return the sequence as a string\n",
    "            length += 1  # increment the sequence length\n",
    "    \n",
    "    seq.pop(0)  # remove the start token\n",
    "    return ' '.join(seq)  # return the sequence as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What to Do If Youre a Victim of Plagiarism You 're trawling the internet one day and say that\n",
      " How Long Does It Take to Write a Book ? How long is a piece of writing , \"\n",
      " Publisher Word Count for Magazine Writing When you write for print magazines and newspapers .\n",
      " Its Okay to be a strong one rather than a content mill that is taking your labor and giving\n",
      " Former vs Latter with Examples here 's a statement that seems to contradict itself , but they only see\n",
      " Earth Island Journal , a glossy quarterly magazine of Earth Island Institute , its a word .\n",
      " Although there are many others .\n",
      " 50 Creative Writing Ideas and Prompts When it comes to that .\n",
      " Random Word Generator is a tool which will do exactly that for you by easily allowing you to change\n",
      " Create Your Optimal Writing Place : 1000 Words a Day Writing Challenge If you find this tool useful in\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):  # generate 10 random sequences with max_len 20 using 4-grams\n",
    "    print(generate_rand_seq(FourGram_Dict, 20, start_sequences_4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TVKnc-5QKs8i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Plural Possessives : Why You Put an Apostrophe After the S Its common for people to wonder , \"\n",
      " A Fine Parent Pays Writers $100 Per Article \" You 're a dumbass , \" or , \" The\n",
      " Simple Ways to Improve Your Writing Vocabulary A great vocabulary is just one essential tool in a writers toolbox\n",
      " Although there are many opinions on how many types of essays there are , everyone seems to agree on\n",
      " Scary Mommy Pays Freelance Writers $100 per Article If it was published in newsprint , Scary Mommy would be\n",
      " Stumbling into a Freelance Writing Career When people find out that I 'm a professional writer .\n",
      " Become a Better Writer : Preserve and Improve Your Reading Skills Its no secret that reading and writing go\n",
      " 10 Common Writing Submission Mistakes Writers are sometimes their own worst enemies .\n",
      " WEB PAGE WORD COUNTER Non-Common Keywords Keyword Quantity All Keywords Keyword Quantity There may be certain times when instead\n",
      " 20 Helpful and Fun Products for Writers Most writers do n't need a lot of words to cover the\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):  # generate 10 random sequences with max_len 20 using 5-grams\n",
    "    print(generate_rand_seq(FiveGram_Dict, 20, start_sequences_5, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Between 4 and 5 gram:\n",
    "There does not seem to be much difference from the above sentences, however, almost all of the sentences generated by 5-gram seem to make sense while the same can not be said for the sentences generated by 4-grams. This is may be due to the fact that probably starting with 4 words makes the 5-gram model has only one choice to go since the dataset has only one option matching this sequence therefore the model will be just completing a single sentence in the dataset so it will make sense as it is not putting together words from different sentences"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Language Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
